{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e95dd62-954d-4cce-aa11-11889dfd9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from typing import List\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils.multiclass import type_of_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e22f3af-ae1c-4820-b3f0-cf0f90c4d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_features(X: pd.DataFrame, target_column, threshold: float = 0.01) -> List[str]:\n",
    " \n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Determine if the task is classification or regression\n",
    "    target_type = type_of_target(y)\n",
    "\n",
    "\n",
    "    if target_type in ['binary', 'multiclass']:\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "    elif target_type in ['continuous', 'continuous-multioutput']:\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported target type: {}\".format(target_type))\n",
    "\n",
    "    model.fit(X, y)\n",
    "    # Get feature importance\n",
    "    importance = model.feature_importances_\n",
    "\n",
    "    feature_importance = pd.Series(importance, index=X.columns).sort_values(ascending=False)\n",
    "    # Select features above the importance threshold\n",
    "    important_features = feature_importance[feature_importance > threshold].index.tolist()\n",
    "    \n",
    "    return important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7580c853-5065-4397-80ec-0ec60d7f0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "\n",
    "    if model_name == '1':\n",
    "        model = KNeighborsRegressor()\n",
    "    elif model_name == '2':\n",
    "        model = KNeighborsClassifier()\n",
    "    elif model_name == '3':\n",
    "        model = DecisionTreeRegressor(random_state=42)\n",
    "    elif model_name == '4':\n",
    "        model = DecisionTreeClassifier(random_state=42)\n",
    "    elif model_name == '5':\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "    elif model_name == '6':\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "    elif model_name == '7':\n",
    "        model = LinearRegression()\n",
    "    elif model_name == '8':\n",
    "        model = LogisticRegression(random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type: {}\".format(model_name))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54d37e7b-6651-426c-a4db-7a3550ba02d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrices(model, X_test, y_test, problem_type):\n",
    "   \n",
    "    metrics = {}\n",
    "\n",
    "    if problem_type == 'regression':\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Regression metrics\n",
    "        metrics['MSE'] = mean_squared_error(y_test, y_pred)\n",
    "        metrics['RMSE'] = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        metrics['MAE'] = mean_absolute_error(y_test, y_pred)\n",
    "        metrics['R-squared'] = r2_score(y_test, y_pred)\n",
    "\n",
    "    \n",
    "    elif problem_type == 'classification':\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Classification metrics\n",
    "        metrics['Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "        metrics['Precision'] = precision_score(y_test, y_pred, average='weighted')\n",
    "        metrics['Recall'] = recall_score(y_test, y_pred, average='weighted')\n",
    "        metrics['F1-Score'] = f1_score(y_test, y_pred, average='weighted')\n",
    "        # Confusion Matrix\n",
    "        metrics['Confusion Matrix'] = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b70a6f53-edcb-4cb8-8917-a0c26a12a76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter file path:  winequality-red.csv\n",
      "Enter label name:  quality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=======================\n",
      "1. KNN - regression\n",
      "2. KNN - classifier\n",
      "3. DT - Regression\n",
      "4. DT - Classifier\n",
      "5. RF - Regression\n",
      "6. RF - Classifier\n",
      "7. Linear Regression\n",
      "8. Logistic Regression\n",
      "=======================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select the model from above list (enter the number):  4\n"
     ]
    }
   ],
   "source": [
    "def get_pickle_filename(model_name):\n",
    "    filenames = {\n",
    "        '1': \"KNeighborsRegressor_model_pickle.pkl\",\n",
    "        '2': \"KNeighborsClassifier_model_pickle.pkl\",\n",
    "        '3': \"DecisionTreeRegressor_model_pickle.pkl\",\n",
    "        '4': \"DecisionTreeClassifier_model_pickle.pkl\",\n",
    "        '5': \"RandomForestRegressor_model_pickle.pkl\",\n",
    "        '6': \"RandomForestClassifier_model_pickle.pkl\",\n",
    "        '7': \"LinearRegression_model_pickle.pkl\",\n",
    "        '8': \"LogisticRegression_model_pickle.pkl\"\n",
    "    }\n",
    "    return filenames[model_name]\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dataset_path = input(\"Enter file path: \")\n",
    "    label_column = input(\"Enter label name: \")\n",
    "    print(\"\\n\\n=======================\")\n",
    "    print(\"1. KNN - regression\\n2. KNN - classifier\\n3. DT - Regression\\n4. DT - Classifier\\n5. RF - Regression\\n6. RF - Classifier\\n7. Linear Regression\\n8. Logistic Regression\")\n",
    "    print(\"=======================\\n\\n\")\n",
    "\n",
    "    model_name = int(input(\"Select the model from above list (enter the number): \"))\n",
    "\n",
    "    df = pd.read_csv(dataset_path)\n",
    "\n",
    "    important_features = get_important_features(df, label_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d846358-4157-46d2-9b50-b52c8fd54cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to keep only important features for model fitting\n",
    "df_filtered = df[important_features + [label_column]]\n",
    "\n",
    "X = df_filtered.drop(columns=[label_column])\n",
    "y = df_filtered[label_column]\n",
    "\n",
    "model = get_model(str(model_name))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "473cd3d8-cd8f-4054-af82-08c53a507555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anmol\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:269: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning using GridSearchCV\n",
    "if str(model_name) == '1':  # KNN - regression\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 10],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "elif str(model_name) == '2':  # KNN - classifier\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 10],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "elif str(model_name) == '3':  # DT - Regression\n",
    "    param_grid = {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['auto', 'sqrt', 'log2']\n",
    "    }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "elif str(model_name) == '4':  # DT - Classifier\n",
    "    param_grid = {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['auto', 'sqrt', 'log2']\n",
    "    }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "elif str(model_name) == '5':  # RF - Regression\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['auto', 'sqrt', 'log2']\n",
    "    }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "elif str(model_name) == '6':  # RF - Classifier\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['auto', 'sqrt', 'log2']\n",
    "    }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "elif str(model_name) == '7':  # Linear Regression\n",
    "    param_grid = {\n",
    "        'normalize': [True, False],\n",
    "        'fit_intercept': [True, False]\n",
    "    }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "elif str(model_name) == '8':  # Logistic Regression\n",
    "    param_grid = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'solver': ['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga']\n",
    "    }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid model selection.\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "regression_models = [1, 3, 5, 7]\n",
    "classification_models = [2, 4, 6, 8]\n",
    "\n",
    "if model_name in regression_models:\n",
    "    problem_type = 'regression'\n",
    "elif model_name in classification_models:\n",
    "    problem_type = 'classification'\n",
    "else:\n",
    "    raise ValueError(\"Invalid user input. Expected values are 1 to 8.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b203c224-db0a-4a58-9846-b74d404d3e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saving the pickledmodel inDecisionTreeClassifier_model_pickle.pkl\n",
      "\n",
      "Model Evaluation Metrics (classification):\n",
      "{'Accuracy': 0.559375, 'Precision': 0.558787563938619, 'Recall': 0.559375, 'F1-Score': 0.5583180489101541, 'Confusion Matrix': array([[ 0,  0,  1,  0,  0,  0],\n",
      "       [ 0,  3,  3,  4,  0,  0],\n",
      "       [ 0,  3, 87, 37,  3,  0],\n",
      "       [ 1,  5, 37, 74, 13,  2],\n",
      "       [ 0,  1,  2, 21, 15,  3],\n",
      "       [ 0,  0,  0,  2,  3,  0]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "# Save the model as a pickle file\n",
    "output_model_path = get_pickle_filename(str(model_name))\n",
    "print(f\"\\nsaving the pickledmodel in{output_model_path}\\n\")\n",
    "with open(output_model_path, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "\n",
    "metrics = get_metrices(best_model, X_test, y_test, problem_type)\n",
    "print(f\"Model Evaluation Metrics ({problem_type}):\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1ce34b-cd5e-48ea-967e-b2fa1ff3b787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
